# -*- coding: utf-8 -*-
"""Submission2_TimeSeries.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oim9-EDWsgp8GkNl9pKhoCSeCalitX7v
"""

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf

df = pd.read_csv('/content/hour.csv', index_col='dteday')
df

df = df.drop(['instant', 'atemp', 'weekday', 'casual', 'registered'], axis=1)
df

train_dataset = df.sample(frac=0.8,random_state=0).astype(float)
test_dataset = df.astype(float)

train_labels = train_dataset.pop('cnt').astype(float).values
test_labels = test_dataset.pop('cnt').astype(float).values

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
train_dataset= scaler.fit_transform(train_dataset)
train_labels = train_labels.reshape(-1,1)
train_labels = scaler.fit_transform(train_labels)

train_dataset

train_dataset = train_dataset[:, np.newaxis]
train_dataset.ndim

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[1:]))
    return ds.batch(batch_size).prefetch(1)

train_dataset.ndim

train_dataset.shape

from keras.layers import Bidirectional

model = tf.keras.models.Sequential([
  Bidirectional(LSTM(units=64, return_sequences=True,go_backwards=True)),#,dropout=0.5, recurrent_dropout=0.5,activation='relu'
  tf.keras.layers.Dense(32, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=['mae', 'mse','accuracy'])

threshold = (train_dataset.max() - train_dataset.min()) * 10/100
threshold

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')<threshold):
      print("\nMAE telah mencapai > 10% dari skala data!")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(
    train_dataset,
    train_labels, 
    epochs=1000, 
    batch_size=32, 
    validation_split=0.2,
    shuffle=False,
    callbacks=[callbacks]
)

import matplotlib.pyplot as plt
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Mean Average')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('ACC')
plt.ylabel('ACC')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

